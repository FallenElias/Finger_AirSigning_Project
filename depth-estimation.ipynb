{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JhxPGQUfn_HI"
      },
      "outputs": [],
      "source": [
        "# All imports\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rquzn8zhn_HK"
      },
      "outputs": [],
      "source": [
        "def recordVideo(output):\n",
        "    cap = cv2.VideoCapture(0)\n",
        "    # Define the codec and create a VideoWriter object\n",
        "    size = (\n",
        "        int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
        "        int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n",
        "    )\n",
        "    out = cv2.VideoWriter(output, cv2.VideoWriter_fourcc(*'mp4v'), 30, size)\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if ret:\n",
        "            out.write(frame)\n",
        "            # Write the frame to the output file\n",
        "            frame = cv2.flip(frame, 1)\n",
        "\n",
        "            # Display the resulting frame\n",
        "            cv2.imshow('frame', frame)\n",
        "\n",
        "            # Exit recording if 'q' is pressed\n",
        "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                break\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    # Release resources\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    cv2.waitKey(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "P81_jfOHn_HL"
      },
      "outputs": [],
      "source": [
        "def video_tracking(original_video_path, depth_video_path):\n",
        "    # sourcery skip: low-code-quality\n",
        "    # finger sur une vidéo\n",
        "\n",
        "    # Set up video capture from default camera\n",
        "    cap = cv2.VideoCapture(original_video_path)\n",
        "    depth = cv2.VideoCapture(depth_video_path)\n",
        "\n",
        "    # Set up MediaPipe hand detection\n",
        "    mpHands = mp.solutions.hands\n",
        "    hands = mpHands.Hands()\n",
        "    mpDraw = mp.solutions.drawing_utils\n",
        "\n",
        "    # Initialize list of finger positions\n",
        "    finger_positions = []\n",
        "    images = []\n",
        "    # Main loop for video capture and hand detection\n",
        "    imageCompteur = 0\n",
        "    while cap.isOpened():\n",
        "        # Capture a frame from the camera\n",
        "        success, image = cap.read()\n",
        "\n",
        "        # Check if the frame was successfully read\n",
        "        if not success:\n",
        "            break\n",
        "\n",
        "        if depth.isOpened():\n",
        "            # Capture a frame from the camera\n",
        "            success_depth, image_depth = depth.read()\n",
        "\n",
        "            # Check if the frame was successfully read\n",
        "            if not success_depth:\n",
        "                break\n",
        "\n",
        "            image = cv2.flip(image, 1)\n",
        "            image_depth = cv2.flip(image_depth, 1)\n",
        "\n",
        "            mask = image_depth > 220\n",
        "            sumMask = sum(sum(sum(mask)))\n",
        "\n",
        "            # Convert the color space of the image from BGR to RGB\n",
        "            imageRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Use MediaPipe to detect hand landmarks in the image\n",
        "            results = hands.process(imageRGB)\n",
        "\n",
        "            # Check if any hands were detected in the image\n",
        "            if results.multi_hand_landmarks:\n",
        "                # Loop through all detected hands\n",
        "                for handLms in results.multi_hand_landmarks:\n",
        "                    # Loop through all the landmarks of the current hand\n",
        "                    hasHeight = False\n",
        "                    for id, lm in enumerate(handLms.landmark):\n",
        "                        # Get the pixel coordinates of the landmark\n",
        "                        h, w, c = image.shape\n",
        "                        cx, cy = int(lm.x * w), int(lm.y * h)\n",
        "\n",
        "                        # If the current landmark is the tip of the index finger, add its position to the list\n",
        "                        if id == 8:\n",
        "                            hasHeight = True\n",
        "                            # image_depth[cy][cx][0] > 220 :\n",
        "                            if sumMask > 115000:\n",
        "                                finger_positions.append((cx, cy))\n",
        "                                cv2.circle(image, (cx, cy), 10,\n",
        "                                           (255, 0, 255), cv2.FILLED)\n",
        "                                imageCompteur = 0\n",
        "                            else:\n",
        "                                imageCompteur += 1\n",
        "\n",
        "                    if not hasHeight:\n",
        "                        imageCompteur += 1\n",
        "                    if imageCompteur >= 5:\n",
        "                        finger_positions.append(\"stop\")\n",
        "                        imageCompteur = 0\n",
        "\n",
        "                    # Draw the landmarks and connections on the image using MediaPipe\n",
        "                    mpDraw.draw_landmarks(\n",
        "                        image, handLms, mpHands.HAND_CONNECTIONS)\n",
        "\n",
        "            # If there are any finger positions in the list, draw a curve passing through all of them\n",
        "            finger_positions.append(\"stop\")\n",
        "            if finger_positions:\n",
        "                # split array\n",
        "                curve = []\n",
        "                for i in finger_positions:\n",
        "                    if i != \"stop\":\n",
        "                        curve.append(i)\n",
        "                    elif len(curve) > 0:\n",
        "                        curve = np.array(curve)\n",
        "                        cv2.polylines(image, [curve], False, (255, 0, 0), 3)\n",
        "                        curve = []\n",
        "            finger_positions.pop()\n",
        "\n",
        "            # Display the image on the screen\n",
        "            cv2.imshow(\"Output\", image)\n",
        "            images.append(image)\n",
        "\n",
        "            # Check for the Esc key to stop the program\n",
        "            if cv2.waitKey(5) & 0xFF == 27:\n",
        "                break\n",
        "\n",
        "    # Define the codec and create VideoWriter object\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    savePath = depth_video_path.split('\\\\')[0] + \"\\\\tracking.mp4\"\n",
        "\n",
        "    out = cv2.VideoWriter(savePath, fourcc, 30, (640, 480))\n",
        "    print(f\"video save at: {savePath}\")\n",
        "\n",
        "    # Main loop for writing video\n",
        "    for img in images:\n",
        "        out.write(img)\n",
        "\n",
        "    out.release()\n",
        "    # Release the video capture object and close all windows\n",
        "    cap.release()\n",
        "    depth.release()\n",
        "    cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "iijXuJCYo9lj"
      },
      "outputs": [],
      "source": [
        "def midas_prediction(frame):\n",
        "    #start = time.time()\n",
        "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    input_batch = transform(img).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        prediction = midas(input_batch)\n",
        "\n",
        "        prediction = torch.nn.functional.interpolate(\n",
        "            prediction.unsqueeze(1),\n",
        "            size=img.shape[:2],\n",
        "            mode=\"bicubic\",\n",
        "            align_corners=False,\n",
        "        ).squeeze()\n",
        "    output = prediction.cpu().numpy()\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "RyaGtJg4ovg2"
      },
      "outputs": [],
      "source": [
        "def midas_depthVideo(video_path):\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    video_path = video_path.split('\\\\')[0] + \"\\depth_video.mp4\"\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    size = (\n",
        "        int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
        "        int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n",
        "    )\n",
        "    video = cv2.VideoWriter(video_path, fourcc, 30, size)\n",
        "    for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
        "        is_read, frame = cap.read()\n",
        "        if is_read:\n",
        "            output = midas_prediction(frame)\n",
        "            formatted = (output * 255 / np.max(output)).astype(\"uint8\")\n",
        "            img = Image.fromarray(formatted)\n",
        "            img.save('img.jpg')\n",
        "            image = cv2.imread('img.jpg')\n",
        "            video.write(image)\n",
        "        else:\n",
        "            break\n",
        "    cap.release()\n",
        "    video.release()\n",
        "    print(\"La vidéo a été créée avec succès !\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "ngEMisrZn_HN",
        "outputId": "406d87b3-cf2c-42e9-ba7c-5716ada37a39"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /Users/quentin/.cache/torch/hub/intel-isl_MiDaS_master\n",
            "Using cache found in /Users/quentin/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La vidéo a été créée avec succès !\n"
          ]
        }
      ],
      "source": [
        "# main\n",
        "output = 'video\\init.mp4'\n",
        "#recordVideo(output)\n",
        "\n",
        "# Model selection\n",
        "model_type = \"DPT_Large\"      # MiDaS v3 - Large     (highest accuracy, slowest inference speed)\n",
        "#model_type = \"DPT_Hybrid\"     # MiDaS v3 - Hybrid    (medium accuracy, medium inference speed)\n",
        "#model_type = \"MiDaS_small\"      # MiDaS v2.1 - Small   (lowest accuracy, highest inference speed)\n",
        "\n",
        "#Model Loading\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type)\n",
        "device = torch.device(\n",
        "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "midas.to(device)\n",
        "midas.eval()\n",
        "\n",
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
        "\n",
        "if model_type == \"DPT_Large\" or model_type == \"DPT_Hybrid\":\n",
        "    transform = midas_transforms.dpt_transform\n",
        "else:\n",
        "    transform = midas_transforms.small_transform\n",
        "\n",
        "#Depth video creation\n",
        "video_path = midas_depthVideo(output)\n",
        "video_tracking(output, video_path)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
